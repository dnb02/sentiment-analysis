{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fEZy2qudQZQ3",
        "Bo0Gvf4NsPdk"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN CODE!!!"
      ],
      "metadata": {
        "id": "uDCcTL5VwzQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "path=\"/content/drive/MyDrive/ProjectFiles/reviewzz\"\n",
        "\n",
        "reviews_pos = os.listdir(path+\"/pos\")\n",
        "reviews_neg = os.listdir(path+\"/neg\")\n",
        "reviews=[]\n",
        "for i in reviews_pos:\n",
        "  reviews.append(i)\n",
        "for i in reviews_neg:\n",
        "  reviews.append(i)\n",
        "r=[]\n",
        "for i in reviews_pos:\n",
        "  f=open(path+'/pos/'+i,mode='rb')\n",
        "  no_ascii=remove_non_ascii_1(str(f.read()))\n",
        "  r.append((no_ascii,i))\n",
        "  f.close()\n",
        "for i in reviews_neg:\n",
        "  f=open(path+'/neg/'+i,mode='rb')\n",
        "  no_ascii=remove_non_ascii_1(str(f.read()))\n",
        "  r.append((no_ascii,i))\n",
        "  f.close()\n"
      ],
      "metadata": {
        "id": "BD6nbybysUKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.DataFrame(r)\n",
        "df['label']=df[1].apply(lambda x: 1 if x[0:3]=='pos' else 0)\n",
        "df.columns=['review','file_name','label']"
      ],
      "metadata": {
        "id": "lFVTDK5p5jIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_non_ascii_1(text):\n",
        "  return ''.join([i if ord(i) < 128 else ' ' for i in text])"
      ],
      "metadata": {
        "id": "BmGO6TgkIXUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report\n",
        "X_train,X_test,y_train,y_test=train_test_split(df.review,df.label,test_size=0.2)\n",
        "\n",
        "v = CountVectorizer()\n",
        "X_train = v.fit_transform(X_train).toarray()\n",
        "model=GaussianNB()\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "X_test = v.transform(X_test).toarray()\n",
        "y_pred=model.predict(X_test)\n",
        "print(classification_report(y_test,y_pred))\n"
      ],
      "metadata": {
        "id": "DwPSMYY329Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "X_train,X_test,y_train,y_test=train_test_split(df.review,df.label,test_size=0.2)\n",
        "v= CountVectorizer()\n",
        "model = SVC()\n",
        "X_train_cv=v.fit_transform(X_train)\n",
        "X_test_cv=v.transform(X_test)\n",
        "model.fit(X_train_cv,y_train)\n",
        "y_pred=model.predict(X_test_cv)\n",
        "print(classification_report(y_pred,y_test))\n"
      ],
      "metadata": {
        "id": "OWoHkqCIvnFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e45d3ada-a07f-4b8f-d5eb-c4aaa05f82cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.70      0.76       164\n",
            "           1       0.66      0.82      0.73       116\n",
            "\n",
            "    accuracy                           0.75       280\n",
            "   macro avg       0.75      0.76      0.75       280\n",
            "weighted avg       0.77      0.75      0.75       280\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88DDGM-Oxhko",
        "outputId": "f18d6882-4ec8-4043-9ae4-e4a7ed54fc06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'the most imaginative part of mallrats comes with its opening credits , which are blatantly sexual comic book pictures--and that\\'s not too imaginative either . the biggest laugh in mallrats , from an audience of 11-12-year-olds assembled in rows 15 and 16 , came when the two protagonists-buddies consult a fortune teller who bares her top and exhibits three nipples . ( number three , of course , is a fake , but the boys are taken in ) . even then , it was only size 4 or 5 laughter on a scale of 1 to 10 . the view of american youth in mallrats tries to be funny , which it isn\\'t . it might have been a satire of slackers and mall culture but it isn\\'t that either . it\\'s plain dull and just a series of nails in the american coffin . the filmmaker is kevin smith , whose feature writer-director debut was clerks , an original , plotless comedy of people in and around a convenience and a video store . the absurdist , slice-of-life , desultorily conversational and pointedly scatological clerks was a hit , though i had my reservations about it . mallrats , done in the same spirit and with some of the same actors ( smith himself playing silent bob ) , is a flop . it has something of a plot , vague and disjointed . t . s . ( notice the scatology of the name ) ( jeremy london ) has been dumped by his fiancee brandi ( claire forlani ) for reasons too dull to mention . brodie ( jason lee ) , has been dumped by his girl rene ( shannen doherty ) because , in bed , he is more interested in video-games than in sex . ( let\\'s not even talk about love ) . the two men ( men ? ) find solace in doing what any red-blooded idiots will do . they go to the mall . there , a subplot has them trying to sabotage that day\\'s forthcoming game show , a kind of dating game , which is produced by brandi\\'s father , a youthful but bald creep . the movie\\'s comedy is below sitcom level , the dialogue , action and characters are of no interest , except perhaps to people under twenty with a mental age under six . since those people neither read film reviews nor put any credence in adult judgments , mallrats might just have a career , even though it is exceptionally thin and dull in every way . the best that can be said is that , at the mall , smith places a fat young man who stares at a sort of pointillist painting which , looked at with concentration , reveals a sailboat . but the poor fellow stands there and stands there and can\\'t see a thing . not a bad gag , though thoroughly milked . another \" funny \" item is about a fifteen-year old girl who is presumably so bright that she\\'s a senior . she is writing a book about orgasms and researches by sleeping with men right and left and videotaping the activities . her language is raunchy even by kevin smith standards , standards that use the alphabet from the a-word to perhaps some z-word , though the n-word is not heard . the fun and games are uncoordinated and slipshod . the film might have used updated marx brothers strategies instead of applying a para-clerks style which relies on frail crutches instead of tempo , energy or the occasional witticism . there are also other inconsistencies . in her letter of resignation , so to speak , brodie\\'s girl lists his defects . brodie thinks that \" callow \" is the only nice thing in the letter , yet he will occasionally use a hi-fallutin\\' word . we also think for a long time that brodie and co . are high-schoolers , but are told at the end that they are college students . somehow , comic-book author and icon stan lee shows up , gives sage advice to brodie . it might have been amusing , it is merely artificial . and here and there are tentative take-offs , but these do not take off . \\r\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to Improve your Model?\n",
        "1. Using Cross Validation to train your data\n",
        "2. Finetuning your Hyperparameters\n",
        "3. Adding context to your data(most cumbersome)"
      ],
      "metadata": {
        "id": "ZkMKbNiLUY8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Cross Validation"
      ],
      "metadata": {
        "id": "qDG3LRqEWi7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from pandas import *\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=108)"
      ],
      "metadata": {
        "id": "vq_8Dm4gUXax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "df=pd.read_csv(\"spam.csv\",encoding='ISO-8859-1')\n",
        "df=df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1)\n",
        "df['spam']=df['v1'].apply(lambda x: 1 if x=='spam' else 0)\n",
        "df.columns=['category','text','spam']\n",
        "df=df.drop(['category'],axis=1)\n",
        "X=df"
      ],
      "metadata": {
        "id": "ib17Jw0XZ_s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=5, random_state=None)\n",
        "# X is the feature set and y is the target\n",
        "for train_index, test_index in skf.split(X,y):\n",
        "    print(\"Train:\", train_index, \"Validation:\", val_index)\n",
        "    X_train, X_test = X[train_index], X[val_index]\n",
        "    y_train, y_test = y[train_index], y[val_index]"
      ],
      "metadata": {
        "id": "fIFNX27aYLSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(DataFrame.split)"
      ],
      "metadata": {
        "id": "epzv6hwKbrDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "TxSK4TngaG6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of Features New Implementations\n",
        "\n",
        "Naive Bayes, MNB and GNB <br>\n",
        "Support Vector Machines"
      ],
      "metadata": {
        "id": "wYSAH_1hSsDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fit_transform() and transform()\n",
        "#fit transform, the model gets fitted according to data\n",
        "#transform, the model does not get fitted according to data, parameters like mean, variance(in kmeans, svectors in svm, etc) are unknown, so it doesnt learn from this set\n",
        "#we can use fit_transform also but it will learn, and our data will no longer be the surprise we want it to be, so we dont do that\n",
        "\n"
      ],
      "metadata": {
        "id": "CJnO_KZQS42_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(df.text,df.spam,test_size=0.2)\n",
        "v= CountVectorizer()\n",
        "model = SVC()\n",
        "X_train_cv=v.fit_transform(X_train)\n",
        "X_test_cv=v.transform(X_test)\n",
        "model.fit(X_train_cv,y_train)\n",
        "y_pred=model.predict(X_test_cv)\n",
        "print(classification_report(y_pred,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNTYnCDdYhTI",
        "outputId": "fa0d975d-4702-4c23-dd5f-582134afd9cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99       980\n",
            "           1       0.86      1.00      0.92       135\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.93      0.99      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gaussiannb takes dense input ie arrays\n",
        "#multinomialnb takes sparse matrix input\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(df.text,df.spam,test_size=0.2)\n",
        "v = CountVectorizer()\n",
        "X_train = v.fit_transform(X_train)\n",
        "model=MultinomialNB()\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "X_test = v.transform(X_test)\n",
        "y_pred=model.predict(X_test)\n",
        "print(classification_report(y_test,y_pred))\n"
      ],
      "metadata": {
        "id": "Msyg99FBXGgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gaussiannb takes dense input ie arrays\n",
        "#multinomialnb takes sparse matrix input\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(df.text,df.spam,test_size=0.2)\n",
        "v = CountVectorizer()\n",
        "X_train = v.fit_transform(X_train).toarray()\n",
        "model=GaussianNB()\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "X_test = v.transform(X_test).toarray()\n",
        "y_pred=model.predict(X_test)\n",
        "print(classification_report(y_test,y_pred))\n"
      ],
      "metadata": {
        "id": "rYwOi33JSV8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "bM9UgjciXZTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing bag of features model"
      ],
      "metadata": {
        "id": "fEZy2qudQZQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#label info on sarcasm if yes then negate, better than nothing\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ArCN0PQ9Qi1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"spam.csv\",encoding='ISO-8859-1')\n",
        "df=df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1)\n",
        "df['spam']=df['v1'].apply(lambda x: 1 if x=='spam' else 0)\n",
        "df.columns=['category','text','spam']"
      ],
      "metadata": {
        "id": "mHTX9lM0UEhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(df.text,df.spam,test_size=0.2)"
      ],
      "metadata": {
        "id": "_P3yXED9RCWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train)\n",
        "dir(X_train)"
      ],
      "metadata": {
        "id": "JsKcHVVcXqa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "pl=Pipeline([\n",
        "  ('vector', CountVectorizer()),\n",
        "  ('svec',SVC())\n",
        "])\n",
        "pl1=Pipeline([\n",
        "  ('vector', CountVectorizer()),\n",
        "  ('nb',MultinomialNB())\n",
        "])"
      ],
      "metadata": {
        "id": "-77WEL6YX1VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl.fit(X_train,y_train)\n",
        "print(classification_report(y_test,pl.predict(X_test)))"
      ],
      "metadata": {
        "id": "w4hgv_VIZddi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "v = CountVectorizer()\n",
        "print(type(v))\n",
        "X_train_cv = v.fit_transform(X_train)\n",
        "print(type(X_train_cv))\n",
        "print(v.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvdC731lvCvc",
        "outputId": "ab854af6-e0f9-44bd-f538-930aa3015bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "['00' '000' '000pes' ... 'ûïharry' 'ûò' 'ûówell']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Playing around with Dictionaries"
      ],
      "metadata": {
        "id": "Bo0Gvf4NsPdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict ={}\n",
        "dict[\"deva\"]=7\n",
        "dict[\"meva\"]=2"
      ],
      "metadata": {
        "id": "zk_b2Ug0eQdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNtRoTkUeQgB",
        "outputId": "17fd2dbf-0120-44ee-aa30-d479ccc5aed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'deva': 7, 'meva': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict[\"hoka\"]=9\n",
        "print(dict[\"hoka\"])"
      ],
      "metadata": {
        "id": "I18IPRQHfBIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf29bbad-4f7d-4e62-ba53-ae0beb3e5f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dict.keys())\n",
        "print(dict.values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFvwFxB3eQlQ",
        "outputId": "9fade7f4-17cf-4353-9a4f-d6a0f0e2a7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_values([7, 2])\n",
            "dict_keys(['deva', 'meva'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Trying Pickle to save trained models"
      ],
      "metadata": {
        "id": "aZ1WPNhPsV89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "Db_ULi-seQn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = load_diabetes(return_X_y=True, as_frame=True)\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=69)"
      ],
      "metadata": {
        "id": "Tt7cmVXoeQs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modal = XGBClassifier()\n",
        "modal.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "124FbztfeQvt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "509efd61-c382-4e9a-f95d-191f1957ed57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(objective='multi:softprob')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Whaat the hell this code does?\n",
        "\n",
        "\n",
        "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
        "              importance_type='gain', interaction_constraints='',\n",
        "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
        "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
        "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
        "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
        "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
        "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
        "'''"
      ],
      "metadata": {
        "id": "AUW4SY5QeQyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(modal,open('model.pkl',\"wb\"))"
      ],
      "metadata": {
        "id": "KGrBtNX6eQ0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickled_xgb=pickle.load(open('model.pkl',\"rb\"))\n",
        "pickled_xgb.predict(X_test)"
      ],
      "metadata": {
        "id": "5kD3f6XDeQ3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File Handling in Python"
      ],
      "metadata": {
        "id": "tiUUVUwotL15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "path=\"/content/drive/MyDrive/ProjectFiles/reviews\"\n",
        "\n",
        "reviews = os.listdir(path)\n",
        "for i in reviews:\n",
        "  f=open(path+'/'+i)\n",
        "  print(f.read().decode('utf-8', errors='ignore').encode('utf-8'))\n",
        ""
      ],
      "metadata": {
        "id": "s-3JXYL1tQ9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3B-Sa8zU0DRo",
        "outputId": "93798c3f-ef33-4209-822c-18cb3dec6ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'UTF-8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}